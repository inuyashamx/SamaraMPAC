#!/usr/bin/env python3
"""
Script de prueba para verificar que OpenAI funciona con contextos largos
"""

from samara.smart_conversational_agent import SmartConversationalAgent

def test_contexto_largo():
    """Prueba con un contexto mÃ¡s largo que deberÃ­a activar OpenAI"""
    print("ğŸš€ Iniciando prueba de contexto largo con OpenAI...")
    
    # Inicializar con perfil de dev (sin recuerdos para contexto mÃ¡s limpio)
    agent = SmartConversationalAgent(profile_path="profiles/dev.json")
    
    # Mensaje que incluye mucho contexto
    mensaje_largo = """
    Necesito ayuda para analizar el mÃ³dulo login del proyecto sacs3. 
    
    Este proyecto es muy complejo y tiene muchas dependencias. El mÃ³dulo de login maneja:
    - AutenticaciÃ³n de usuarios
    - ValidaciÃ³n de credenciales  
    - GestiÃ³n de sesiones
    - IntegraciÃ³n con Firebase
    - Manejo de errores de autenticaciÃ³n
    - RedirecciÃ³n despuÃ©s del login
    - Tokens de seguridad
    - EncriptaciÃ³n de contraseÃ±as
    
    TambiÃ©n necesito entender cÃ³mo se integra con otros mÃ³dulos del sistema,
    las dependencias que tiene, los endpoints que expone, y cualquier 
    patrÃ³n de diseÃ±o que estÃ© utilizando.
    
    El sistema completo tiene mÃ¡s de 100 mÃ³dulos y necesito una explicaciÃ³n
    detallada que me ayude a entender la arquitectura completa.
    
    Â¿Puedes hacer un anÃ¡lisis completo del mÃ³dulo login y su contexto?
    """
    
    print(f"ğŸ“ Mensaje de prueba: {len(mensaje_largo)} caracteres")
    print("="*50)
    
    # Hacer la consulta
    respuesta = agent.interactuar("test_user", mensaje_largo)
    
    print("="*50)
    print("ğŸ“‹ RESPUESTA:")
    print(respuesta)
    
    # Mostrar estadÃ­sticas
    print("\nğŸ“Š ESTADÃSTICAS DEL ROUTER:")
    stats = agent.model_router.get_stats()
    print(f"Total requests: {stats['total_requests']}")
    print(f"Por proveedor: {stats['by_provider']}")
    if 'by_context_size' in stats:
        print(f"Por tamaÃ±o de contexto: {stats['by_context_size']}")

def test_cambio_manual_openai():
    """Prueba forzando el uso de OpenAI"""
    print("\nğŸ”„ Probando cambio manual a OpenAI...")
    
    agent = SmartConversationalAgent(profile_path="profiles/dev.json")
    
    # Forzar uso de OpenAI
    respuesta1 = agent.interactuar("test_user", "usar modelo gpt")
    print(f"Respuesta al cambio: {respuesta1}")
    
    # Hacer consulta simple
    respuesta2 = agent.interactuar("test_user", "Â¿QuÃ© modelos tienes disponibles?")
    print(f"Respuesta: {respuesta2}")

def test_proveedores_disponibles():
    """Verificar quÃ© proveedores estÃ¡n disponibles"""
    print("\nğŸ” Verificando proveedores disponibles...")
    
    agent = SmartConversationalAgent(profile_path="profiles/dev.json")
    available = agent.model_router.get_available_providers()
    
    print(f"Proveedores disponibles: {available}")
    
    if 'gpt4' in available:
        print("âœ… OpenAI/GPT-4 estÃ¡ disponible")
    else:
        print("âŒ OpenAI/GPT-4 NO estÃ¡ disponible - verifica tu API key")
    
    if 'ollama' in available:
        print("âœ… Ollama estÃ¡ disponible")
    else:
        print("âŒ Ollama NO estÃ¡ disponible")

if __name__ == "__main__":
    print("ğŸ§ª PRUEBAS DE CONTEXTO LARGO Y OPENAI")
    print("="*60)
    
    # Verificar proveedores disponibles primero
    test_proveedores_disponibles()
    
    # Probar cambio manual
    test_cambio_manual_openai()
    
    # Probar contexto largo
    test_contexto_largo()
    
    print("\nâœ… Pruebas completadas") 